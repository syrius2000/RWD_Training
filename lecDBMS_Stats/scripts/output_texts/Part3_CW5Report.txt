
  社内データベースから自動的な異常検知について
  観測できない潜在情報を積極利用した自動アノマリー検出
  
  山口 学
  安全管理部
  2016/08
    





異常検知(anomaly detection)する道具の提案 

Introduction and 振り返り

[containsverbatim]
  どのようなデータを分析対象にしたか？

  安全性自発報告のシステム(CW5と通称。以下DB)から期間を設定。
  情報源を「自発報告」とし、因果関係、重篤性、未知など制限を加えない
  (本文で展開する時系列分析では、文献情報等のモデル化は困難であり除外) 。

  
  
  

  
    DBの主な取扱い
      
        [情報抽出期間] 最新8年と設定
        [index1] 「第一報情報入手日」を月単位でグルーピング
        [index2] 薬剤CODE（入力そのまま）をグルーピング
        [index3] 有害事象名をMedDra用語PT単位でグルーピング
        




[containsverbatim]
  従来の情報の見方・その改善

  従来の情報の見方
    
      条件抽出した一覧表やその単純集計
      閾値、すなわち「定数」の利用。
        
          未知症例が、（閾値）XX例したら・・・
          重篤例が（閾値）XX例したら・・・
            



# A tibble: 2 x 4
  YEARMON   CODE                       PT  YOBS
   <fctr> <fctr>                   <fctr> <int>
1 2013_06    FBX アナフィラキシーショック     1
2 2013_03    FBX アナフィラキシーショック     1
    
  

[allowframebreaks]
  単純一覧表には、情報処理上の問題がある

    一覧表形式は経時変化が把握しにくい 
      DB抽出は存在するもののみを一覧化。「０」情報が「情報落ち」する。

      「０」情報が無いと時系列分析に制限が加わる。
      
        稀な有害事象における「情報落ち」が特に大きいので・・・
          
            「全DB中XXX件」など、一律な定数による判断
            「平均XX例」などの現状把握が困難
            将来の発生見積もりがKKD
                  基礎統計値（平均、分散など）が正しく得られないので・・・
          
            分母の情報が欠落
                    

  XX件発生・・・が多いか少ないか？という客観性評価が困難
  報告数のみを利用すると過大・過少評価の恐れ！


  「０」の出力・その他情報の整備
    多くの情報システムが持つ、「共通の弱点」を改善
    
      基礎統計値（平均、分散など）が得られる
      母数が得られる
        
          確率モデルによる期待値が得られる
          確率を利用した客観的な anomary detection
              自然な情報処理で正しく結果を導ける
        
          自由に誰もが情報処理・要約できる
          技能不要で経時的変化の把握ができる
          グラフ化して解釈しやすい
              
    データ構造を工夫すれば、多くの情報が得られる！



  [shrink]利用したdatabaseの構造

  代表的データ構造の列名称・内容
        
    
      YEARMON
        
          20080901から20160831までの96か月で、時点"200801"などを示す
              YOBS
        
          当該月に報告された件数。有害事象と薬剤組み合わせ単位
          「０」情報を含む
              ICSRSMONTH
        
          当該月に報告された、薬剤その全部の数。報告率算出用
              MASS
        
          DB中に月単位で何月報告されたか(命名田崎)（96か月の場合,0～96）
              CODE
        
          社内の医薬品分類コード（英字3 or 4文字）
              PT
        
          MedDRAのPT和名
              BETA
        
          対象DBに保存されている「ある薬剤の総レコード数」（期間内全合計数）
                
  
 

[containsverbatim]
  利用したdatabaseの概要
  

  代表的な列の単純集計
    
      薬剤CODE domain濃度
        
          176件
              PT domain濃度
        
          1404件
              薬剤  PT組わせ
        
          [理論的組み合わせ]   247104組
          [存在する組み合わせ] 6905組（0%）
              
  例えばFBXの光線過敏性反応は報告事例がない。



> dbsql 

# A tibble: 0 x 14
# ... with 14 variables: YEARMON <fctr>, CODE <fctr>, SOC <fctr>, PT <fctr>, YOBS <int>, ICSRS <int>,
#   ALPHA <int>, BETA <int>, ALPHA0 <int>, BETA0 <int>, RWNUM <int>, MASS <int>, PT_MASS <int>, DRUG_MASS <int>

存在割合は0%と情報粗密行列の状態だった。





[containsverbatim]
  ０例も把握できる良いデータ構造の利用
    FBXアナフィラキシーショック
        


> getYobsData(code = "FBX", pt = "アナフィラキシーショック")

# A tibble: 96 x 7
   YEARMON  YOBS ICSRS  MASS   CODE                       PT  BETA
    <fctr> <dbl> <dbl> <int> <fctr>                   <fctr> <int>
 1 2009_08     0     0     2    FBX アナフィラキシーショック   640
 2 2009_09     0     0     2    FBX アナフィラキシーショック   640
 3 2009_10     0     0     2    FBX アナフィラキシーショック   640
 4 2009_11     0     0     2    FBX アナフィラキシーショック   640
 5 2009_12     0     0     2    FBX アナフィラキシーショック   640
 6 2010_01     0     0     2    FBX アナフィラキシーショック   640
 7 2010_02     0     0     2    FBX アナフィラキシーショック   640
 8 2010_03     0     0     2    FBX アナフィラキシーショック   640
 9 2010_04     0     0     2    FBX アナフィラキシーショック   640
10 2010_05     0     0     2    FBX アナフィラキシーショック   640
# ... with 86 more rows




[containsverbatim,allowframebreaks]
    確率モデルが使いやすい組み合わせ
      
  「報告」という事象を巧く説明するモデルとしてポアソン分布がある。
  
 

  還元論的に、有害事象「報告」もこの法則に従うと考えるのが自然。

  ポアソン分布は、母数をとした時、事象Xの確率，期待値、分散、累積分布関数はそれぞれ下記に従う
 。



ポアソン分布に従う事象は、母数，期待値、分散が等しいことが要請される。

 


  これを実データで確認し、利用する。

FMXA の薬疹報告を取り上げる。




> (dat <- getYobsData(code = "FMXA", pt = "薬疹") 

# A tibble: 96 x 2
   YEARMON  YOBS
    <fctr> <dbl>
 1 2009_08     2
 2 2009_09     0
 3 2009_10     1
 4 2009_11     0
 5 2009_12     0
 6 2010_01     1
 7 2010_02     0
 8 2010_03     0
 9 2010_04     1
10 2010_05     0
# ... with 86 more rows

> datYOBS)

[1] 0.458

> mean(datYOBS)^2

[1] 0.457

> mean(datYOBS^2) - mean(datMASS > 6)
> dat6 

.
FALSE  TRUE 
92.14  7.86 

> dat30 <- (datMASS > 6MASS > 30MASS > 3  dat定数母数推定確率分散平均Shape母数 = 1をデータから得た場合、

    
      有意水準（1-）を設定する。
      P.のCMF関数から95%の確率は、「5件以下」と分かる
      5件以下は「異常判定保留」として翌月を見る
      6件以上の発生は、（以前と同じでない事から）異常と見做す
        
    パラメータをデータから求めれば、「1例発生確率はXX%」、「2例はYY%」
    と分かるので、累積して有意水準95%までの発生は許容する。

    「それを超えた」モノを機械的に抽出する。 これは逐次直接確率検定を行う事に該当。
    検定を用いた「異常検知」が客観的・機械的に実現できる。
    
 

    この様に、anomaly 異常があれば、自動的に識別できる




    課題の把握

   上昇傾向を示す例・多峰性を示す例
  
    CYM の悪心（報告数上昇傾向）
    PRS の光線過敏症（多峰性）
    
  他社先行研究 で、安全性情報はポアソン分布が利用
  できる事に加えて、ゼロ修正モデルによる推定が良い事を報告した。
  
 

  しかし、修正モデルは一般に単峰を示す対象にしか使えない。

  一方、事例のように上昇傾向を示すモノや多峰性を示すモノが存在する。
  
 

  全ての事象を説明できる万能モデルが、存在しない事は21世紀に証明されている
  (no-free-lunch theorem(NFLT「あらゆる問題で性能の良い汎用最適化戦略は
  理論上不可能であり、ある戦略が他の戦略より性能がよいのは、現に解こうとしている
  特定の問題に対して特殊化（専門化）されている場合のみである」)) 。
  我々はデータに合わせて妥当なモデルを選択するべきである。




    Introduction解決方法の紹介
  
  下降傾向・上昇傾向を示すモノや、多峰性を示すものであっても、
  異常検知に役立つ・有用なツールが求められる。
  
 

  （ある程度それを満たす）
  
 

  
    機械的に分析し、分類し、可視化
    する方法を開発したので報告する。




課題となるケースの把握とその対処


    CYMの悪心
        
            

    GoodFit test for Poisson Dist. CYMの悪心
        

    PRSの光線過敏性反応
        
            

    GoodFit test for Poisson Dist. PRSの光線過敏症
         


    なぜあてはまり具合が悪いのか？

    原因は、「平均」を代表として推論するには無理なデータ構造をしているため。
    
 

    ある試行で「平均」で発生した事象は、別試行でも平均バラツキで発生とするのは自然。
    また、データが大量に得られれば、「大数の弱法則」により必ず平均に収束する。
    
 

    だが、前提に必用な仮定「独立・同分布、期間中の平均が一定(i.i.d.)で大量データ」は、
    市販後では馴染まない。
    P.で示したようにDBの情報量は、「疎」である。
    季節性も考慮が必用。
    
 

    全ての期間中に有害事象の発生率が、「一定」という仮定もまた強すぎる。
    
 

    変化が「存在するか」を見張る業務に、期間中「一定」を仮定するのは逆である。



[containsverbatim,allowframebreaks]
    説明困難な事例にどう対応するか？

    混合モデルという同一分布が複数混合した場合を考えるのが尤も簡単。

    「i.i.d条件を満たさない事象」即ち複雑な事象を説明できるモデルとして利用できる。
    
 


  潜在クラスモデル(Latent class model)
    モデルの尤度関数は、左辺の
    をパラメータベクトルとし、を混合率、
    、を分布固有パラメータとした時
     eq:FiniteMixtureModelとなる。

    

    混合率情報は観測できない潜在情報であり、「潜在クラスモデル」と一般化される。
  
    FDAシグナル指標EBGMやWHOのBCPNNで既に利用されており我々に馴染み深い。
  有限混合分布モデル(finite mixture distributions model)とも言われる。

  FDA、WHOを真似て、ある分布が２つ混合していると定義するのが自然であり、
  広くは計量経済でも利用される 。

  尤度関数 eq:FiniteMixtureModelのパラメータベクトル  を推定する。
  

    潜在変数は背景にある分布個々のパラメータ 、を峻別する。
    このモデルは初等数学で解析解が得られない。 よって、数値計算法で推定することになる。

  潜在クラスモデルの推定方法
    
      BFGS法(準ニュートン法.1970 by Broyden, Fletcher, Goldfarb and Shanno)など反復法で最適解を推定
      EM Algorithmで最適解を推定
        (http://cs229.stanford.edu/notes/cs229-notes8.pdf解説PDF参照)
      マルコフ連鎖モンテカルロ法で最適解を推定
        (Markov chain Monte Carlo methods simulation:MCMCの枠組みでMH法,Gibbs法等を利用)
      (その他)モーメントからの線形代数で解く(問題ごとにSystem equationが必用で高度)
      (その他)グラフを書いてK.K.D(Kan, Keiken and Dokyo)
        


    推定方法メリット・デメリット
  
  利用できるパラメータ推定方法の中で、自動化の観点で優れた方法を選択する。
  各種推定の枠組みについてはが詳しい。

  尤も効率的と判断したEM algorithm(http://pianopiano.sakura.ne.jp/ml/em-algorithm/解説参照)
  による推定を利用した。P. に基礎原理を記載する。

  推定方法のPros., Cons.
              
    反復法は殆どの統計ソフトが対応。モデル、データ、初期値に関する知識が必要であり、
  大量・自動処理が一般に困難。
  
 

  EM Algorithmは初期値に関わらず、反復毎に最適解に収束することが証明されている。

  E-Step、M-Stepは其々独立に推定できる特徴を持ち、新型CPUでの並列化も可能。
  MCMCに比べ4-5桁速い。効率的であり、自動化に良い。
  http://www.slideshare.net/sotetsukoyamada/em-36315279URL資料参照

  MCMCは乱数が定義できるモノは、全て推定可能で初期値問題も殆どない。

  原理的に長時間計算が必用であり、今回行った計算時間は「10日」。

  

情報を加味したグラフ・その効果


    PRSの具体例でパラメータを推定


    P. のPRS-光線過敏症のグラフに結果を重ねる。

    「PRS－光線過敏性反応」の推定結果
      パラメータは推定結果は、それぞれ
      、、となった。

    
      はの混合割合で、約0.6の期間で月平均と推定
      はの混合割合で、約の期間で月平均と推定
        

    ビジネスマンにとって、数理の意味やプログラミング、エンジニアリングの価値よ
  り、 結果がどうかが気になる。





  再掲：PRS-光線過敏症反応
        
          


  PRS－光線過敏性反応の混合率推定
  


    もう少し改良

    P. のモデル eq:FiniteMixtureModel式のは
    混合率を示す潜在パラメータであった。これを用いると有用な情報が得られる。
    
 

    ベイズの定理を利用して事後確率を求めれば、 どちらに所属しているかを確率的に
    峻別できる。この峻別を機械学習では「クラスタリング」という。

    P. の式 eq:FiniteMixtureModel
    に所属情報を加えて書き直し、幾つかの数学的操作の後に次式を得る。

   

     eq:clastering式により、個別のデータXの事後確率が得られる。
    判定は、「事後確率がならのに分類。
    それ以外ならのに分類。」と機械的に峻別できる。
    
 

    専門知識を必要とせず、対象データから機械的にクラス分類するこの方法は、
    「教師なしデータ」の「クラスタリング（分類）」と呼ばれる。




    PRSの光線過敏性反応の潜在モデル推定（横線）
    
             


    CYMの悪心、潜在モデル推定（横線）
    
             


     解釈例

     異なる傾向が一目瞭然（ではなかろうか）。

     PRSの光線過敏性反応
       直後調査期間？にある月ピークが存在。その後月平均0.6件に減少。

       最近1年では月平均4件と発売初期に比べて約6倍の上昇。差は3例の上昇。
     
     CYMの悪心
         直後調査時？に月平均約6件報告であった。この2.3年に上昇傾向が認められる。
         最近1年は平均約47件と発売初期に比べ、6倍弱の上昇。差は42例上昇。
     
     グラフだけでは読み取りにくい「変化点」を読み取れるので便利である。 

     しかし、「増加・減少傾向」を把握しにくい。
     
 

     移動平均で平滑化し、変動把握を容易にする。 （最終提案までもうすこし）




    PRSの光線過敏性反応（潜在クラスプロット）
    
             


    CYMの悪心（潜在クラスプロット）
    
             


    報告PTの占拠率

  
  有害事象の報告「数」の上昇が見られた場合、 効能追加などで薬剤自体の「
  総報告数」増加が主要因の場合がある。

  有害事象の「報告割合」はその薬剤で不変だとしても、
  薬剤「総報告数」が増えると、「数」は 「見かけ上」増加する。

  

  
  この報告の割合期待値は全期間一定と仮定するのが自然。

  

  有害事象の月単位の「報告割合」を求め、パネルグラフを完成版とし
  て全品目で作成する。
  
 

  http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/PDFlist.html
  グラフはこちらのWebで後悔




    PRS-光線過敏性反応事例の完成版グラフ 
    )
             


    CYM-悪心事例の完成版グラフ 
    
             


  対策提案例

  グラフを見て自然な解釈すれば、発生傾向の特徴をつかめるかもしれない。
  なぜそれが発生するのか？などについての議論や、これからどうするかについて
  議論の材料にしていただきたい。

  PRSの光線過敏性反応
    他社類似品の上市もあり、再度光線過敏症についての対策について丁寧な情報
    提供が必用となる可能性もある。
  
  CYMの悪心
    重要な戦略品目に該当し、悪心などQOLを損なう事象の上昇傾向が投与・量の増加の抵抗
    になっている可能性がある。丁寧な情報提供などが必用かもしれない。
  
  専門家にゆだねる。




異常検知と自動識別の枠組み

異常検知のための台帳作成

[containsverbatim]
    異常検知の枠組み１






  各種パラメータの算出と一覧化
      
          基礎統計量（平均、分散、平均／分散比）
          ZTPモデルのパラメータ推定
          潜在クラスモデルのパラメータ推定
          その他
        あらかじめ全ての組み合わせを抽出し、計算し台帳化する。
  http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/Theta.csv（こちらのWebに保管）
  
    集計期間を適宜定め(現在は直近8年間（20090801から20170731）
  を設定)、 薬剤（濃度176種類） PT（濃度1404種類）の組み合わせ中の、
  存在する組み合わせ全て(6905)に対して、上記を例に統計的フレームワークを適用して、台帳化する。
  
 

  計算スケジュールは自由。逐次データ処理（毎日、毎週、毎月）可能
  
  
  




    異常検知の枠組み２

  閾値設定がいったん完了すれば、その後は機械的な情報処理が可能。
  機械的に全ての組み合わせについて網羅的にスキャンできる。
  
 

  たとえば四半期に、すべてを確認するなど定めた期間で確認し続ければよい。
  「閾値」設定は協議して設定する必要がある。
  
 

  多様なヒトを含めた検討により、感覚バイアスの影響があるかもしれない。
  そこで、近年専門知識を用いなくとも、情報エントロピーや多次元距離による類似度
  を用いた自動分類が確立している。これによる分類結果をまず提供する。
  
 

  自動的にグループ分けし、ヒトの解釈を加え、再度分類を調整するサイクルにより、
  より完成度の高い自動検知プログラムを作成を目指す。このサイクルにより、
  エキスパートシステムの構築が可能になる。




    (提案なのに未完）自動分類総説


  仮題:CW5計測分析の骨子
  平均月報告数を分析して全体像を把握する
    
      ABC分析
      過大分散・過少分散の組み合わせざくっと把握
      Appendix：確率を用いる準備
      
  (未完: 組み合わせ結果の構成図を作る）

    CW5の中身を全体的に把握する報告書を準備中。

  (Draft: http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/CW5CODEBOOK.pdf
               CW5計測分析はこちらのWeb）




自動的な分類について


    類似度・乖離度によるクラスタリング

      プログラム完成するも説明困難。事例報告不備φ(..)メモメモとして。

  
    事例＃１
      
        ROW：PT-Drug、COL:生データ発生期間の表（巨大）を作成、発生例数を scalingして、正規化。
        階層クラスターの重心を評価。
        クラス階層数決定問題をBICで自動設定。近代的。
          事例＃２
      
        基礎統計値の重心距離を対象にした上記階層・k-meansのクラス分けを行う。
        古典的Multi-dimensional scaling はエッジが平均化。分類能失う。
          事例＃3
      
        LBPでの輪郭把握が傾向把握に役立ちそうと確信（作成開始）
        二値化関数、ヒストグラム化、類似度計算（interaction）、クラス分けを書く
        
    ここのパートは自由度が大きく、ヒトの協力により評価結果をSVM, SOMで分析。
    空間切って条件化。将来データにぶつけて汎用性を評価するのも「超有用（と確信）」




  近接距離法による階層類似度

k-近傍法は「教師なし機械学習」の領域で最も多用される手法。
重要な概念が多数存在し、どの領域も省略困難。

 

残念ながら、全部省略し結果だけを示す。 


http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/PDFlist.html
発生傾向変化検知の情報提供ページ参照



    


http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/PDFlist.html
発生傾向変化検知の情報提供ページ にて、
現在全薬剤中80%の情報を提供しているので参照。 目を引く組み合わせを下記に示する。

    CYMのある2PT推移の事例
        http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/CYM_Category2_2PTs.pdf
        CYM 分類番号＃2 発生傾向の上昇を自動分類した事例
    
    PRSのある3PT推移の事例
    http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/PRS_Category2_3PTs.pdf
    PRS 分類番号＃3 発生傾向の上昇を自動分類した事例
    
    FGTのあるPT推移の事例
    http://sui655mfs.scinet.shionogi.co.jp/DataScience/AnomalyDetection/FGT_Category4_1PTs.pdf
    FGT 分類番号＃2 ある期間から傾向変化を自動分類した事例
    
人工知能はいまだ中学生レベルとされる。
だが、パターン認識に於いては画像・音声認識においても機械が人をしのぐ
(安全性情報は「教師なし」学習である。「教師あり」にはDeep Learningが凄んごい)。

すばらしい。そして恐ろしい。




パラメータ推定法


    2nd opition 向け専門的解説

    社内専門家向けに、数理的解説、検討結果を紹介する。

    
          BFGS法など反復計算法
          EM法
          MCMC推定
              
                GibsサンプラーのJAGS利用と結果・速度評価
                NUTアルゴリズムのSTAN利用と結果・速度評価
                

反復法による数値解


    反復数値計算法の概略


    反復数値計算法は、微分・積分などの解を解析的に求められない場合、
    数値計算による近似を求める一般的枠組みをいう。

    を求める時、収束が速いニュートン法が多用される。
    


    その他、黄金比探索、二本木探索など多数のアルゴリズムを問題により選択する。
    関数の最適化問題は計算機に対する知識も必要であり、 広範囲な専門的知識
    と精度良いソフトウエアが必用。

    学生の勉強目的以外、素人には自作の余地がない
    (専門家の意見は総じて「数値計算なめんな！」というもの)。
    
 

    極値からの脱出方法などが改良された(BFGS法など）専用ソフトの利用が推奨される。





  最適化問題の制限

    万能の手法は存在しない
        私の見解では，最適化モデルに取り組んでいる誰もが知っていなければならない（主な）
        ことは，一般的に最適化問題は解けないということである。
           

[containsverbatim,allowframebreaks]
    反復法による推定事例

    解析センター所有の"Infinite mixuter distribution"の例
    ,, で初期値設定の
    困難性を示す。
    
 

    その困難以外にも、P. の式
    eq:FiniteMixtureModelが、ラベル情報が無い故の不確実な挙動も示す。
    
 

    その他、定義から混合率の拘束条件設定、underflow対策など広範囲の知識を
    動員して、対処した。

    結果として、BFGS法を用いても自動化が困難なことが分かった。





> mixOPTIM <- function(thetaINIT = c(0, 1, 2), dat = DataVector) 
+     VecLogLH <- function(theta) 
+         r <- exp(theta[1])/(1 + exp(theta[1]))
+         lambda1 <- exp(theta[2])
+         lambda2 <- exp(theta[3])
+         LL <- sum(log(r * dpois(dat, lambda1) + (1 - r) * dpois(dat, lambda2)))
+         return(LL)
+     
+     INIT <- thetaINIT
+     res <- optim(INIT, VecLogLH, method = "BFGS", hessian = TRUE, control = list(fnscale = -1))
+     return(c(exp(respar[1])), exp(respar[3])))
+ 
> datsample <- c(rep(0, 162), rep(1, 267), rep(2, 271), rep(3, 185), rep(4, 111), rep(5, 
+     61), rep(6, 27), rep(7, 8), rep(8, 3), rep(9, 1))
> .control = "R = 0.28705, lambda1 = 1.10209, lambda2 = 2.58164, n = 1096"
> mixOPTIM(dat = datsample, thetaINIT = c(0.5, 0.4, 2))

[1] 0.36 1.26 2.66

> mixOPTIM(dat = datsample, thetaINIT = c(0.1, 0.4, 2))

[1] 0.64 2.66 1.26

> mixOPTIM(dat = datsample, thetaINIT = c(0.5, 0.4, 4))

[1]  1.00  2.16 54.60


    結果の一行目は、「答えを知っている」とすると良い推定。
    
 

    結果の二行目は、ラベル問題による不確実性が再現されている。
    P.式eq:FiniteMixtureModelの定義には、
    混合率がどちらに所属するか？ という情報が無い。
    初期値次第ではの大小関係も変わる。
    これは「混合分布のラベル問題」と言われる。
    
 

    この問題により 推定の大小関係が変わると、
    条件判断処理が複雑になり大量処理に手間がかかる。
    
 

    結果の三行目は、L2の初期値を変えるとパラメータベクトル全体が違う結果になった。
    
 

    「答えを知っている」とした時でさえ、良い初期値の自動設定は困難。
    これらの問題から、大量の組み合わせを調べるビジネスには、 応用困難と結論づけた。
    





EM Algorithmによる数値解

[allowframebreaks]
    EM法による推定

P.対数尤度関数の式eq:FiniteMixtureModel
に潜在変数を与え所属情報を加える。

潜在変数は、 が第一分布に所属するとき、 1、それ以外の時0を示す確率変数
 。

現実には測定できないこの変数は「欠測」といえるので、データは「欠測データ」と見做せる。
観測できたらそのデータは「擬似完全データ」と定義する。

 

EMアルゴリズムは期待値算出（E-Step）と擬似完全データの最大化（M-Step)を組み合わせて、
巧妙に欠測データを含むモデルの母数推定を実現する。


完全データを仮定した時の対数尤度
  

は、確率の要請とクラス制限が課されている。ある制限化において最適化が必用。

ラグランジュ未定乗数法を利用し、拘束条件変数を含めて定式化する。

最適化すべき対数尤度関数


eq:EMlogThetaを最大化する 一階条件は、偏微分して得られる方程式を解けば良い。

対数尤度関数最大化一階条件


上記の連立方程式を解く。eq:maximization2、eq:maximization3より
、を得る。


eq:maximization1より、を得る。

各、の時、クラス事後確率は
P. の eq:clasteringより得られ、クラス情報になる。

 

E-step、M-stepの方程式が導出できれば勾配法、反復法などで解ける。素晴らしい。

 

鋭い方から、「解析的に解けないといったじゃないか！」とツッコミがありそうだが、
擬似完全情報を仮定するアイディアにより解析的に解けるのである。
21世紀の10大アルゴリズムとも言われ、開発者の素晴らしさに感謝して自分のビジネスに生かす。



[containsverbatim,allowframebreaks]
    EMの実装現場利用

    GitHUB に公開（予定）したプログラム実装例の性能確認を行う。
    混合分布の乱数を発生させる関数を作成し、推定プログラムを検証する。
    
 

    混合割合,第一平均、第二平均
    で乱数を発生させて、推定結果と比較する。

    
    

> dat <- makeMixtureDF(n = 100, r = 0.7, lambda1 = 0.2, lambda2 = 5)
> estimateMixturePoison(datR
[1] 0.702

Lambda2
[1] 5.35

> datn=10010^-10= 0.702_1=0.192_2=5.35= 0.7, _1=0.2, _2=5R = 0.29_1 = 1.10_2 = 2.595000 4R = 0.41_1 = 1.30_2 = 2.75R = 0.36_1 = 1.25_2 = 2.66