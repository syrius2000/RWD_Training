# RDBMSへのインポートTips

ELT（Extract, Load, Transform）プロセスが未整備な環境では、CSVなどのフラットファイルをRDBMSへ適切にインポートする作業が頻繁に発生します。
SQL作成にはDDLレベルの条件が明確でなければならない。 RDBMSへのデータインポートを成功させるためには、以下の点に注意が必要です。

1. カラムの文字列のサイズ長
2. NULL ケースの存在
3. フラットテーブルのEncoding
4. フラットテーブルのレコードセパレータ
5. 重複レコードがある場合はPrimaryが設定できない
6. いわゆる外字とEncodingの問題
7. 構造の不正（カラム数がレコードで一定か？）
8. 複数のフラットファイルにまたがる場合

## 標準的なインポートSQL事例

``` SQL
    CREATE TABLE 患者基本情報_身長体重 (
         PATIENTNO VARCHAR(20) NOT NULL,        -- 患者番号
         SEX VARCHAR(1) NULL,                   -- 性別
         HEIGHTWEIGHTSTATUS VARCHAR(2) NULL,    -- 身長体重ステータス
         HEIGHTWEIGHT DECIMAL(5,2) NULL,        -- 身長または体重（例: 156.7）
         HEIGHTWEIGHTDATE DATE NULL             -- 身長体重測定日
         );
-- csv import
    LOAD DATA LOCAL
        INFILE 'fugafuga'  -- CSVファイルのフルパスを指定
    INTO TABLE 患者基本情報_身長体重                -- データを挿入するテーブル名
    FIELDS TERMINATED BY ','                     -- 各フィールドの区切り文字
    ENCLOSED BY '"'                              -- フィールドを囲む文字（例: ダブルクォート）
    LINES TERMINATED BY '\n'                     -- 各レコードの区切り文字（改行コード）
    IGNORE 1 LINES;                              -- ヘッダー行をスキップする場合
```

## 1. カラムの文字列のサイズ長

RDBMSにデータをインポートする際、各カラムに適切なデータ型とサイズ長を設定することが重要です。特に文字列データ（VARCHARなど）の場合、CSVファイル内の最大文字長を事前に調査し、それに見合ったサイズを設定しないと、データが切り捨てられたり、インポートエラーが発生したりする可能性があります。

## 2. NULL ケースの存在

NULLと空文字列（""）の区別はRDBMSによって挙動が異なる場合があり、注意が必要です。各カラムのNULL許容性（NULLable）を適切に設計することが重要です。CSVファイル内で空欄がNULLを意味するのか、空文字列を意味するのかを明確にする必要があります。

```sql
      SEX VARCHAR(1) NULL,                          -- 性別にもNULLの記録があり得る
```

## 3. フラットテーブルのEncoding

標準的なシェルスクリプトで一括調査する。

```shell
for I in *.txt;do echo $I; nkf --guess $I;done
```
得られた情報をSQLに加える。 `convert_sjis.sql` によって一括で変換できます。

```sql
CHARACTER SET sjis
```

## 4.フラットテーブルのレコードセパレータ

レコードセパレータは、vimなどのテキストエディタでファイルを開いて確認できます（データ入手時のRFPで定義されていることが理想ですが、見落とされがちです）。一般的なセパレータにはカンマ (`,`), タブ (`	`), パイプ (`|`) などがあります。LOAD DATA INFILE文では、`FIELDS TERMINATED BY` オプションで指定します。

## 5. 重複レコードがある場合はPrimaryが設定できない

CSVフラットファイルには重複レコードが含まれる可能性が十分にあります。Primary Keyを設定する前に重複を排除する必要があります。対応策としては、以下の2つが考えられます。
1. RDBMSに一時的にインポートした後、SQLで重複を削除する。
2. インポート前にCSVファイルの段階で重複を削除する。

どちらの方法を選択するかはケースバイケースですが、「重複があること前提での処理」が必要であるという認識が重要です。 コマンドラインツール（例: `sort | uniq` や `awk '!a[$0]++'`）を使った前処理については、`lec01_duplicate_handling` ディレクトリのREADMEを参照してください。

## 6. いわゆる外字とEncodingの問題

フラットファイルに含まれる「外字」（システム標準外の文字）や、ファイルとRDBMSのエンコーディングの不一致は、インポートエラーや文字化けの原因となります。事前に `nkf --guess` などのツールでエンコーディングを調査し、必要に応じて変換を行います。また、外字の有無は目視や特定のスクリプト（例: Pythonで文字コードエラーを捕捉する）で確認し、トライ＆エラーで対応することが多いです。LOAD DATA INFILE文では `CHARACTER SET` オプションで指定します。

## 7. 構造の不正（カラム数がレコードで一定か？）

フラットファイルの構造が不正（例: レコードごとにカラム数が異なる）な場合、インポートエラーが発生します。`awk` などのコマンドラインツールで事前に構造を調査することが重要です。例えば、カラム数のチェックには `awk -F',' '{print NF}' file.csv | sort -nu | uniq -c` のようなコマンドが有効です。また、各カラムの最大文字数、0/1データが文字列か数値か、外字の有無なども確認が必要です。これらの問題には一般的な万能策は少なく、データの内容に応じた試行錯誤（トライ＆エラー）が不可欠です。

## 8. 複数のフラットファイルにまたがる場合

複数のフラットファイルを同じテーブルにインポートする場合、個別の `LOAD DATA INFILE` ステートメントを記述するか、シェルスクリプトなどでループ処理を行い自動化することが考えられます。

```sql
LOAD DATA INFILE '検査_2020txt'
INTO TABLE 一般検査
...
...
LOAD DATA INFILE '検査_2021.txt'
INTO TABLE 一般検査
```
